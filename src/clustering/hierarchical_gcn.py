# src/clustering/hierarchical_gcn.py
"""
å±‚æ¬¡ GCN èšç±»ç³»ç»Ÿ
ä¸‰çº§èšç±»æ¶æ„ï¼šMicro â†’ Meso â†’ Macro
"""
import sys
from pathlib import Path


PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
import torch
import torch.nn as nn
import numpy as np
from sklearn.cluster import KMeans, DBSCAN, SpectralClustering
from typing import Dict, List, Tuple, Optional

from src.models.gcn_encoder import GCNEncoder, normalize_adjacency
from src.features.graph_builder import DynamicGraphBuilder


class HierarchicalGCNClustering:
    """
    å±‚æ¬¡ GCN èšç±»ç³»ç»Ÿ

    ä¸‰çº§æ¶æ„:
    - Micro Level:  å®¢æˆ·ç«¯å†…éƒ¨æ•°æ®èšç±»ï¼ˆK-Meansï¼‰
    - Meso Level:   å®¢æˆ·ç«¯é—´å…³ç³»èšç±»ï¼ˆGCN + Spectralï¼‰
    - Macro Level:  å…¨å±€ç¨³å®šæ€§åˆ†æï¼ˆæ—¶é—´åºåˆ—èšç±»ï¼‰
    """

    def __init__(self,
                 n_clients: int,
                 feature_dim: int,
                 embedding_dim: int = 64,
                 n_micro_clusters: int = 5,
                 n_meso_clusters: int = 3,
                 device: str = 'cpu'):
        """
        Args:
            n_clients: å®¢æˆ·ç«¯æ•°é‡
            feature_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
            embedding_dim: GCN åµŒå…¥ç»´åº¦
            n_micro_clusters: Micro çº§èšç±»æ•°
            n_meso_clusters: Meso çº§èšç±»æ•°
        """
        self.n_clients = n_clients
        self.feature_dim = feature_dim
        self.embedding_dim = embedding_dim
        self.n_micro_clusters = n_micro_clusters
        self.n_meso_clusters = n_meso_clusters
        self.device = device

        # GCN ç¼–ç å™¨
        self.gcn_encoder = GCNEncoder(
            n_features=feature_dim,
            hidden_dim=128,
            embedding_dim=embedding_dim,
            n_layers=3
        ).to(device)

        # å›¾æ„å»ºå™¨
        self.graph_builder = DynamicGraphBuilder(
            n_clients=n_clients,
            threshold_method='adaptive',
            k_nearest=3
        )

        # å†å²è®°å½•
        self.embedding_history = []
        self.cluster_history = {
            'micro': [],
            'meso': [],
            'macro': []
        }

        print(f"\nâœ… HierarchicalGCNClustering initialized:")
        print(f"   Clients: {n_clients}")
        print(f"   Feature dim: {feature_dim}")
        print(f"   Embedding dim: {embedding_dim}")
        print(f"   Micro clusters: {n_micro_clusters}")
        print(f"   Meso clusters: {n_meso_clusters}")

    def cluster_hierarchical(self,
                             client_features: np.ndarray,
                             dtw_distances: np.ndarray,
                             round_idx: int) -> Dict:
        """
        æ‰§è¡Œä¸‰çº§å±‚æ¬¡èšç±»

        Args:
            client_features: å®¢æˆ·ç«¯ç‰¹å¾ [N, D]
            dtw_distances: DTW è·ç¦»çŸ©é˜µ [N, N]
            round_idx: å½“å‰è½®æ¬¡

        Returns:
            èšç±»ç»“æœå­—å…¸
        """
        results = {
            'round': round_idx,
            'micro': None,
            'meso': None,
            'macro': None
        }

        # ==================== Micro Level ====================
        print(f"\n  ğŸ”¬ Micro-level clustering...")
        micro_labels = self._cluster_micro(client_features)
        results['micro'] = {
            'labels': micro_labels,
            'n_clusters': len(np.unique(micro_labels))
        }
        self.cluster_history['micro'].append(micro_labels)

        # ==================== Meso Level ====================
        print(f"  ğŸ” Meso-level clustering (GCN)...")
        meso_labels, embeddings = self._cluster_meso(
            client_features,
            dtw_distances
        )
        results['meso'] = {
            'labels': meso_labels,
            'n_clusters': len(np.unique(meso_labels)),
            'embeddings': embeddings
        }
        self.cluster_history['meso'].append(meso_labels)
        self.embedding_history.append(embeddings)

        # ==================== Macro Level ====================
        if len(self.embedding_history) >= 5:  # è‡³å°‘ 5 è½®
            print(f"  ğŸŒ Macro-level clustering...")
            macro_labels = self._cluster_macro()
            results['macro'] = {
                'labels': macro_labels,
                'n_clusters': len(np.unique(macro_labels))
            }
            self.cluster_history['macro'].append(macro_labels)
        else:
            results['macro'] = {'labels': meso_labels}  # å‰æœŸä½¿ç”¨ Meso ç»“æœ

        # æ‰“å°èšç±»ç»“æœ
        self._print_clustering_summary(results)

        return results

    def _cluster_micro(self, features: np.ndarray) -> np.ndarray:
        """
        Micro çº§èšç±»ï¼ˆå®¢æˆ·ç«¯å†…éƒ¨ï¼‰
        ä½¿ç”¨ K-Means
        """
        kmeans = KMeans(
            n_clusters=self.n_micro_clusters,
            random_state=42,
            n_init=10
        )
        labels = kmeans.fit_predict(features)
        return labels

    def _cluster_meso(self,
                      features: np.ndarray,
                      dtw_distances: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Meso çº§èšç±»ï¼ˆå®¢æˆ·ç«¯é—´ï¼‰
        ä½¿ç”¨ GCN + Spectral Clustering
        """
        # 1. æ„å»ºå›¾
        adj, graph_info = self.graph_builder.build_graph_from_dtw(dtw_distances)
        adj = adj.to(self.device)

        # 2. å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ
        adj_norm = normalize_adjacency(adj)

        # 3. GCN ç¼–ç 
        features_torch = torch.FloatTensor(features).to(self.device)
        embeddings = self.gcn_encoder.get_embeddings(features_torch, adj_norm)
        embeddings_np = embeddings.cpu().numpy()

        # 4. è°±èšç±»
        # spectral = SpectralClustering(
        #     n_clusters=self.n_meso_clusters,
        #     affinity='nearest_neighbors',
        #     n_neighbors=3,
        #     random_state=42
        # )
        n_neighbors = max(2, min(5, embeddings_np.shape[0] - 1))
        spectral = SpectralClustering(
            n_clusters=self.n_meso_clusters,
            affinity='nearest_neighbors',
            n_neighbors=n_neighbors,
            random_state=42
        )
        labels = spectral.fit_predict(embeddings_np)

        return labels, embeddings_np

    def _cluster_macro(self) -> np.ndarray:
        """
        Macro çº§èšç±»ï¼ˆå…¨å±€ç¨³å®šæ€§ï¼‰
        åŸºäºåµŒå…¥å†å²çš„æ—¶é—´åºåˆ—èšç±»
        """
        # å–æœ€è¿‘ 10 è½®çš„åµŒå…¥
        recent_embeddings = self.embedding_history[-10:]

        # è®¡ç®—æ—¶é—´ç»´åº¦çš„ç»Ÿè®¡ç‰¹å¾
        temporal_features = []
        for client_id in range(self.n_clients):
            client_trajectory = [emb[client_id] for emb in recent_embeddings]
            client_trajectory = np.array(client_trajectory)  # [T, D]

            # ç»Ÿè®¡ç‰¹å¾
            mean_traj = np.mean(client_trajectory, axis=0)
            std_traj = np.std(client_trajectory, axis=0)
            trend = client_trajectory[-1] - client_trajectory[0]  # è¶‹åŠ¿

            feature = np.concatenate([mean_traj, std_traj, trend])
            temporal_features.append(feature)

        temporal_features = np.array(temporal_features)

        # K-Means èšç±»
        kmeans = KMeans(
            n_clusters=self.n_meso_clusters,
            random_state=42
        )
        labels = kmeans.fit_predict(temporal_features)

        return labels

    def get_cluster_weights(self, cluster_labels: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—èšç±»æƒé‡ï¼ˆç”¨äºèšåˆï¼‰
        æƒé‡ âˆ 1 / cluster_size
        """
        weights = np.zeros(self.n_clients)

        for cluster_id in np.unique(cluster_labels):
            cluster_mask = (cluster_labels == cluster_id)
            cluster_size = np.sum(cluster_mask)

            # è¾ƒå°çš„ç°‡è·å¾—æ›´å¤§çš„æƒé‡
            weights[cluster_mask] = 1.0 / cluster_size

        # å½’ä¸€åŒ–
        weights = weights / np.sum(weights)

        return weights

    def aggregate_by_clusters(self,
                              client_models: List,
                              cluster_labels: np.ndarray,
                              global_model) -> None:
        """
        åŸºäºèšç±»çš„åŠ æƒèšåˆ

        Args:
            client_models: å®¢æˆ·ç«¯æ¨¡å‹åˆ—è¡¨
            cluster_labels: èšç±»æ ‡ç­¾
            global_model: å…¨å±€æ¨¡å‹ï¼ˆå¾…æ›´æ–°ï¼‰
        """
        # è®¡ç®—æƒé‡
        weights = self.get_cluster_weights(cluster_labels)

        # åŠ æƒèšåˆ
        global_dict = global_model.state_dict()

        for key in global_dict.keys():
            global_dict[key] = torch.zeros_like(global_dict[key])

            for i, model in enumerate(client_models):
                global_dict[key] += weights[i] * model.state_dict()[key].float()

        global_model.load_state_dict(global_dict)

    def _print_clustering_summary(self, results: Dict):
        """æ‰“å°èšç±»æ‘˜è¦"""
        print(f"\n  ğŸ“Š Clustering Summary (Round {results['round']}):")
        print(f"     Micro: {results['micro']['n_clusters']} clusters")
        print(f"     Meso:  {results['meso']['n_clusters']} clusters")

        # æ‰“å° Meso ç°‡åˆ†å¸ƒ
        meso_labels = results['meso']['labels']
        for i in range(self.n_meso_clusters):
            clients_in_cluster = np.where(meso_labels == i)[0]
            print(f"       Cluster {i}: {len(clients_in_cluster)} clients {list(clients_in_cluster)}")

        if results['macro'] is not None and 'n_clusters' in results['macro']:
            print(f"     Macro: {results['macro']['n_clusters']} clusters")

    def save_embeddings(self, path: str):
        """ä¿å­˜åµŒå…¥å†å²"""
        np.savez(path,
                 embeddings=np.array(self.embedding_history),
                 cluster_history=self.cluster_history)
        print(f"âœ… Embeddings saved to {path}")

    def load_embeddings(self, path: str):
        """åŠ è½½åµŒå…¥å†å²"""
        data = np.load(path, allow_pickle=True)
        self.embedding_history = list(data['embeddings'])
        self.cluster_history = data['cluster_history'].item()
        print(f"âœ… Embeddings loaded from {path}")

    # ====== è¡¥ä¸ 1ï¼šä»è·ç¦»çŸ©é˜µæ„é€ ä¸´æ—¶ç‰¹å¾ï¼ˆç»™ Micro & Meso ç”¨ï¼‰ ======
    def _build_features_from_distance(self, dist: np.ndarray) -> np.ndarray:
        dist = dist.copy().astype(np.float32)
        np.fill_diagonal(dist, 0.0)
        pos = dist[dist > 0]
        gamma = 1.0 if pos.size == 0 else 1.0 / (float(np.median(pos)) ** 2 + 1e-8)

        # RBF ç›¸ä¼¼åº¦ç­¾å
        S = np.exp(-(gamma * (dist ** 2))).astype(np.float32)  # [N, N]
        np.fill_diagonal(S, 1.0)

        # â€”â€”å…³é”®ï¼šè¾“å‡ºç»´åº¦å¯¹é½ GCN çš„ in_featuresâ€”â€”
        N = S.shape[1]
        D = self.feature_dim
        if D <= N:
            X = S[:, :D]  # è£å‰ªåˆ° D ç»´ï¼ˆä½ ç°åœ¨æ˜¯ D==N==n_clientsï¼‰
        else:
            # éœ€è¦è¡¥ç»´å°±å…ˆæ‹¼ä¸Šç®€å•ç»Ÿè®¡ï¼Œå†ä¸å¤Ÿå†è¡¥ 0
            deg = S.sum(axis=1, keepdims=True)
            dens = ((S > 0.5).sum(axis=1, keepdims=True) / N)
            X = np.concatenate([S, deg, dens], axis=1)
            if X.shape[1] < D:
                X = np.pad(X, ((0, 0), (0, D - X.shape[1])), mode='constant')
        return X.astype(np.float32)

    # ====== è¡¥ä¸ 2ï¼šæä¾›æ—§æ¥å£ cluster(...)ï¼Œé€‚é… run_mstc_fl.py ======
    def cluster(self,
                distance_matrix: np.ndarray,
                adjacency_matrix: np.ndarray) -> Dict:
        """
        å…¼å®¹æ—§è°ƒç”¨ï¼šè¾“å…¥è·ç¦»/é‚»æ¥ï¼Œè¾“å‡ºåŒ…å« micro_clusters çš„å­—å…¸
        """
        # 1) ç”¨è·ç¦»çŸ©é˜µç”Ÿæˆä¸´æ—¶ç‰¹å¾ï¼ˆä¸æ”¹ä½ ç°æœ‰çš„æ•°æ®æµï¼‰
        client_features = self._build_features_from_distance(distance_matrix)  # [N, *]

        # 2) Microï¼šKMeans
        kmeans = KMeans(n_clusters=self.n_micro_clusters, random_state=42, n_init=10)
        micro_labels = kmeans.fit_predict(client_features)

        # 3) Mesoï¼šæ²¿ç”¨ä½ å·²æœ‰çš„ GCN+è°±èšç±»
        meso_labels, embeddings = self._cluster_meso(client_features, distance_matrix)

        # 4) ç»„è£…ä¸ºæ—§æ ¼å¼è¾“å‡ºï¼ˆrun_mstc_fl.py åªç”¨åˆ°äº† micro_clustersï¼‰
        micro_clusters: Dict[int, List[int]] = {}
        for cid in np.unique(micro_labels):
            micro_clusters[int(cid)] = np.where(micro_labels == cid)[0].astype(int).tolist()

        return {
            "micro_clusters": micro_clusters,
            "meso_labels": meso_labels,
            "embeddings": embeddings
        }


if __name__ == "__main__":
    # æµ‹è¯•å±‚æ¬¡èšç±»
    print("ğŸ§ª Testing HierarchicalGCNClustering...")

    # æ¨¡æ‹Ÿæ•°æ®
    n_clients = 10
    feature_dim = 64

    client_features = np.random.randn(n_clients, feature_dim)
    dtw_distances = np.random.rand(n_clients, n_clients)
    dtw_distances = (dtw_distances + dtw_distances.T) / 2
    np.fill_diagonal(dtw_distances, 0)

    # åˆå§‹åŒ–èšç±»ç³»ç»Ÿ
    clustering = HierarchicalGCNClustering(
        n_clients=n_clients,
        feature_dim=feature_dim,
        embedding_dim=32,
        n_micro_clusters=3,
        n_meso_clusters=2
    )

    # æ‰§è¡Œèšç±»ï¼ˆæ¨¡æ‹Ÿ 10 è½®ï¼‰
    for round_idx in range(10):
        print(f"\n{'=' * 60}")
        print(f"Round {round_idx}")
        print(f"{'=' * 60}")

        results = clustering.cluster_hierarchical(
            client_features,
            dtw_distances,
            round_idx
        )

        # æ¨¡æ‹Ÿç‰¹å¾å˜åŒ–
        client_features += np.random.randn(n_clients, feature_dim) * 0.1

    print("\nâœ… All tests passed!")
