# src/features/multiscale_dtw.py
"""
å¤šå°ºåº¦ DTW è·ç¦»èåˆï¼ˆæ”¯æŒæ—¶åºèšåˆï¼‰
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)
import numpy as np
from fastdtw import fastdtw
from typing import List, Dict, Optional


class MultiScaleDTW:
    """
    å¤šå°ºåº¦ DTW è·ç¦»èåˆ

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. æ—¶åºèšåˆï¼šä»å®¢æˆ·ç«¯æ—¶é—´åºåˆ—ç›´æ¥è®¡ç®— DTW
    2. ç‰¹å¾èšåˆï¼šä» MSTR ç‰¹å¾è®¡ç®—æ¬§æ°è·ç¦»
    """

    def __init__(self,
                 scales: List[int] = [5, 10, 20],
                 weights: Optional[List[float]] = None,
                 mode: str = 'timeseries'):  # âœ… æ–°å¢å‚æ•°
        """
        Args:
            scales: æ—¶é—´å°ºåº¦åˆ—è¡¨
            weights: å°ºåº¦æƒé‡
            mode: 'timeseries' æˆ– 'features'
        """
        self.scales = scales
        self.mode = mode

        # åˆå§‹åŒ–æƒé‡
        if weights is None:
            self.weights = np.ones(len(scales)) / len(scales)
        else:
            if len(weights) != len(scales):
                raise ValueError(f"Weights length {len(weights)} != scales length {len(scales)}")
            self.weights = np.array(weights)
            self.weights = self.weights / self.weights.sum()

        print(f"âœ… MultiScaleDTW initialized: mode={mode}, scales={scales}, weights={self.weights}")

    def compute_distance_matrix(self, data: np.ndarray) -> np.ndarray:
        """
        è‡ªåŠ¨æ£€æµ‹è¾“å…¥ç±»å‹å¹¶è®¡ç®—è·ç¦»çŸ©é˜µ

        Args:
            data:
                - æ—¶é—´åºåˆ—å†å²: (T, n_ensemble)
                - ç‰¹å¾çŸ©é˜µ: (n_clients, feature_dim)

        Returns:
            distance_matrix: (n_clients, n_clients)
        """
        n_samples, n_features = data.shape

        # æ ¹æ®åˆå§‹åŒ–æ¨¡å¼é€‰æ‹©è®¡ç®—æ–¹æ³•
        if self.mode == 'timeseries':
            # å¼ºåˆ¶ä½¿ç”¨æ—¶åºèšåˆ
            return self._compute_from_timeseries_history(data)
        elif self.mode == 'features':
            # å¼ºåˆ¶ä½¿ç”¨ç‰¹å¾èšåˆ
            return self._compute_from_features(data)
        else:
            # è‡ªåŠ¨æ£€æµ‹ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            if n_samples > n_features:
                return self._compute_from_timeseries_history(data)
            else:
                return self._compute_from_features(data)

    def compute_distance_matrix_from_client_timeseries(self,
                                                       client_timeseries: Dict[int, np.ndarray]) -> np.ndarray:
        """
        âœ… æ–°å¢æ–¹æ³•ï¼šä»å®¢æˆ·ç«¯æ—¶é—´åºåˆ—å­—å…¸è®¡ç®— DTW è·ç¦»

        Args:
            client_timeseries: {client_id: timeseries}
                timeseries shape: (T,) æˆ– (T, 1)

        Returns:
            distance_matrix: (n_clients, n_clients)
        """
        n_clients = len(client_timeseries)

        # å­˜å‚¨å„å°ºåº¦çš„è·ç¦»çŸ©é˜µ
        scale_matrices = []

        for scale in self.scales:
            D_scale = np.zeros((n_clients, n_clients))

            for i in range(n_clients):
                for j in range(i + 1, n_clients):
                    # è·å–ä¸¤ä¸ªå®¢æˆ·ç«¯çš„æ—¶é—´åºåˆ—
                    ts_i = client_timeseries[i]
                    ts_j = client_timeseries[j]

                    # ç¡®ä¿æ˜¯ 1D æ•°ç»„
                    if ts_i.ndim > 1:
                        ts_i = ts_i.flatten()
                    if ts_j.ndim > 1:
                        ts_j = ts_j.flatten()

                    # æˆªå–æœ€è¿‘ scale ä¸ªæ—¶é—´æ­¥
                    T_i = len(ts_i)
                    T_j = len(ts_j)

                    if T_i < scale:
                        seq_i = ts_i
                    else:
                        seq_i = ts_i[-scale:]

                    if T_j < scale:
                        seq_j = ts_j
                    else:
                        seq_j = ts_j[-scale:]

                    # è½¬æ¢ä¸º float64
                    seq_i = seq_i.astype(np.float64)
                    seq_j = seq_j.astype(np.float64)

                    # è®¡ç®— DTW è·ç¦»
                    dist, _ = fastdtw(
                        seq_i,
                        seq_j,
                        dist=lambda x, y: np.abs(x - y)
                    )

                    D_scale[i, j] = dist
                    D_scale[j, i] = dist

            scale_matrices.append(D_scale)

        # åŠ æƒèåˆ
        D_fused = np.zeros((n_clients, n_clients))
        for w, D_scale in zip(self.weights, scale_matrices):
            D_fused += w * D_scale

        return D_fused

    def _compute_from_timeseries_history(self, em_history: np.ndarray) -> np.ndarray:
        """
        ä» EM å†å²è®¡ç®—è·ç¦»ï¼ˆæ¯ä¸ª EM å¯¹åº”ä¸€ä¸ªè™šæ‹Ÿå®¢æˆ·ç«¯ï¼‰

        Args:
            em_history: (T, n_ensemble)

        Returns:
            distance_matrix: (n_ensemble, n_ensemble)
        """
        T, n_ensemble = em_history.shape
        scale_matrices = []

        for scale in self.scales:
            if T < scale:
                recent_history = em_history
            else:
                recent_history = em_history[-scale:]

            D_scale = np.zeros((n_ensemble, n_ensemble))

            for i in range(n_ensemble):
                for j in range(i + 1, n_ensemble):
                    seq_i = recent_history[:, i].flatten().astype(np.float64)
                    seq_j = recent_history[:, j].flatten().astype(np.float64)

                    dist, _ = fastdtw(
                        seq_i,
                        seq_j,
                        dist=lambda x, y: np.abs(x - y)
                    )

                    D_scale[i, j] = dist
                    D_scale[j, i] = dist

            scale_matrices.append(D_scale)

        D_fused = np.zeros((n_ensemble, n_ensemble))
        for w, D_scale in zip(self.weights, scale_matrices):
            D_fused += w * D_scale

        return D_fused

    def _compute_from_features(self, features: np.ndarray) -> np.ndarray:
        """
        ä»ç‰¹å¾çŸ©é˜µè®¡ç®—æ¬§æ°è·ç¦»

        Args:
            features: (n_clients, feature_dim)

        Returns:
            distance_matrix: (n_clients, n_clients)
        """
        n_clients = features.shape[0]
        D = np.zeros((n_clients, n_clients))

        for i in range(n_clients):
            for j in range(i + 1, n_clients):
                dist = np.linalg.norm(features[i] - features[j])
                D[i, j] = dist
                D[j, i] = dist

        return D

    def update_weights(self, clustering_quality: List[float]):
        """æ ¹æ®èšç±»è´¨é‡æ›´æ–°å°ºåº¦æƒé‡"""
        if len(clustering_quality) != len(self.scales):
            raise ValueError(f"Quality scores length != scales length")

        scores = np.array(clustering_quality)
        exp_scores = np.exp(scores - np.max(scores))
        self.weights = exp_scores / exp_scores.sum()

        print(f"  Updated DTW weights: {self.weights}")


# ==================== æµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    print("ğŸ§ª Testing MultiScaleDTW with timeseries mode...\n")

    # æµ‹è¯• 1: å®¢æˆ·ç«¯æ—¶é—´åºåˆ—å­—å…¸
    print("Test 1: Client timeseries dictionary")
    n_clients = 5
    T = 20

    # æ¨¡æ‹Ÿæ¯ä¸ªå®¢æˆ·ç«¯çš„æ—¶é—´åºåˆ—
    client_timeseries = {}
    for i in range(n_clients):
        # æ¯ä¸ªå®¢æˆ·ç«¯æœ‰ä¸åŒçš„è¶‹åŠ¿
        trend = np.linspace(0.6 + i * 0.05, 0.8 + i * 0.05, T)
        noise = np.random.randn(T) * 0.02
        client_timeseries[i] = trend + noise

    dtw = MultiScaleDTW(scales=[5, 10, 20], mode='timeseries')
    D = dtw.compute_distance_matrix_from_client_timeseries(client_timeseries)

    print(f"  Distance matrix shape: {D.shape}")
    print(f"  Sample distances:")
    print(f"    Client 0 vs 1: {D[0, 1]:.4f}")
    print(f"    Client 0 vs 4: {D[0, 4]:.4f}")
    print(f"    Client 2 vs 3: {D[2, 3]:.4f}\n")

    # æµ‹è¯• 2: EM å†å²è¾“å…¥
    print("Test 2: EM history input")
    em_history = np.random.randn(30, 6)
    D = dtw.compute_distance_matrix(em_history)
    print(f"  Distance matrix shape: {D.shape}\n")

    print("âœ… All tests passed!")
